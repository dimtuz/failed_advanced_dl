{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NYC Real Estate — DNNs, SHAP & Aleatoric Uncertainty (Notebook 2)\n",
        "\n",
        "**Runs right after the cleaning phase.** Follows the professor's workflow: two-headed model (μ + σ²), MC Dropout, Gaussian & Empirical coverage, SHAP for Price / Epistemic / Aleatoric, Trust Map quadrants, and surgical waterfalls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisite: Load cleaned data\n",
        "\n",
        "Either run **notebook copy.ipynb** through the cleaning phase (through the price-filter cell) so `df` is in memory, or save the cleaned dataframe to `data/cleaned_df.parquet` (or `.csv`) and load it in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "if os.environ.get(\"CI\"):\n",
        "    import matplotlib\n",
        "    matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load df if saved; otherwise assume df is in memory (run notebook 1 first)\n",
        "try:\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    if os.path.exists(\"data/cleaned_df.parquet\"):\n",
        "        df = pd.read_parquet(\"data/cleaned_df.parquet\")\n",
        "        print(f\"Loaded df from data/cleaned_df.parquet: {len(df):,} rows\")\n",
        "    elif os.path.exists(\"data/cleaned_df.csv\"):\n",
        "        df = pd.read_csv(\"data/cleaned_df.csv\")\n",
        "        print(f\"Loaded df from data/cleaned_df.csv: {len(df):,} rows\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No saved cleaned df\")\n",
        "except FileNotFoundError:\n",
        "    try:\n",
        "        _ = len(df)\n",
        "        print(f\"Using df from memory: {len(df):,} rows\")\n",
        "    except NameError:\n",
        "        raise RuntimeError(\n",
        "            \"No cleaned dataframe. Run notebook copy.ipynb through the cleaning phase, \"\n",
        "            \"or save cleaned df to data/cleaned_df.parquet (or .csv).\"\n",
        "        )\n",
        "df.head(2)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/dmitrii/Desktop/advanced_dl_project/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No cleaned dataframe. Run notebook copy.ipynb through the cleaning phase, or save cleaned df to data/cleaned_df.parquet (or .csv).",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo saved cleaned df\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
            "\u001b[31mFileNotFoundError\u001b[39m: No saved cleaned df",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     _ = \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m)\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing df from memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'df' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing df from memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     36\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNo cleaned dataframe. Run notebook copy.ipynb through the cleaning phase, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor save cleaned df to data/cleaned_df.parquet (or .csv).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m         )\n\u001b[32m     39\u001b[39m df.head(\u001b[32m2\u001b[39m)\n",
            "\u001b[31mRuntimeError\u001b[39m: No cleaned dataframe. Run notebook copy.ipynb through the cleaning phase, or save cleaned df to data/cleaned_df.parquet (or .csv)."
          ]
        }
      ],
      "id": "6b0aaff7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set seeds (reproducibility)"
      ],
      "id": "f3214b85"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def set_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "set_seeds(42)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d5778728"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature engineering (ensure sub_region & affluence_score exist)\n",
        "\n",
        "If your cleaning already added these, this is a no-op; otherwise we create them so the same feature set works."
      ],
      "id": "a6687ba1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if \"sub_region\" not in df.columns:\n",
        "    df[\"sub_region\"] = df[\"BOROUGH\"].astype(str) + \"_\" + df[\"NEIGHBORHOOD\"].str[:30]\n",
        "if \"affluence_score\" not in df.columns:\n",
        "    df[\"affluence_score\"] = pd.qcut(df[\"SALE PRICE\"].rank(method=\"first\"), q=10, labels=False, duplicates=\"drop\")\n",
        "    df[\"affluence_score\"] = df[\"affluence_score\"].fillna(0).astype(int)\n",
        "\n",
        "borough_dummies = pd.get_dummies(df[\"BOROUGH\"].astype(str), prefix=\"borough\")\n",
        "sub_region_dummies = pd.get_dummies(df[\"sub_region\"].astype(str), prefix=\"sub_region\")\n",
        "X_df = pd.concat([\n",
        "    df[[\"GROSS SQUARE FEET\", \"BUILDING_AGE\", \"affluence_score\"]],\n",
        "    borough_dummies,\n",
        "    sub_region_dummies\n",
        "], axis=1)\n",
        "feature_names = X_df.columns.tolist()\n",
        "feature_cols = feature_names  # professor-style name\n",
        "X = X_df.values\n",
        "\n",
        "y_raw = df[\"SALE PRICE\"].values\n",
        "y = np.log(y_raw)\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_train_raw, y_test_raw = train_test_split(\n",
        "    X, y, y_raw, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_test = scaler_X.transform(X_test)\n",
        "\n",
        "print(f\"Features: {X_train.shape[1]}, Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "print(f\"log(price) range: [{y_train.min():.2f}, {y_train.max():.2f}]\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "acd48325"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two-headed model (μ + σ²) and Aleatoric loss\n",
        "\n",
        "Gaussian NLL in log space; MC Dropout kept at inference for epistemic uncertainty."
      ],
      "id": "0c72e934"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def aleatoric_loss(y_true, y_pred):\n",
        "    mu = y_pred[:, 0:1]\n",
        "    sigma_sq = y_pred[:, 1:2]\n",
        "    epsilon = 1e-6\n",
        "    return tf.reduce_mean(\n",
        "        0.5 * tf.math.log(sigma_sq + epsilon) +\n",
        "        0.5 * tf.math.divide(tf.square(y_true - mu), sigma_sq + epsilon)\n",
        "    )\n",
        "\n",
        "def make_combined_model(n_features):\n",
        "    inputs = Input(shape=(n_features,))\n",
        "    x = Dense(128, activation=\"relu\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x, training=True)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    mu = Dense(1, name=\"mu\")(x)\n",
        "    sigma_sq = Dense(1, activation=\"softplus\", name=\"sigma_sq\")(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=Concatenate()([mu, sigma_sq]))\n",
        "\n",
        "model = make_combined_model(X_train.shape[1])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=aleatoric_loss)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "fbf6989d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and plot learning curve"
      ],
      "id": "f801a551"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[EarlyStopping(patience=15, restore_best_weights=True)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
        "ax.plot(history.history[\"loss\"], label=\"Train NLL\", color=\"teal\", lw=2)\n",
        "ax.plot(history.history[\"val_loss\"], label=\"Val NLL\", color=\"orange\", lw=2)\n",
        "ax.set_title(\"Learning Curve (Negative Log-Likelihood)\", fontsize=14, fontweight=\"bold\")\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1513f010"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MC Dropout inference: epistemic + aleatoric in dollars"
      ],
      "id": "bde0dcb9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "T = 100\n",
        "preds = np.stack([model(X_test, training=True).numpy() for _ in range(T)])\n",
        "all_mu_log = preds[:, :, 0]\n",
        "all_sigma_sq_log = preds[:, :, 1]\n",
        "\n",
        "mu_mean_log = all_mu_log.mean(axis=0)\n",
        "mu_mean_dollars = np.exp(mu_mean_log)\n",
        "\n",
        "epistemic_var_log = all_mu_log.var(axis=0)\n",
        "epistemic_std_log = np.sqrt(epistemic_var_log)\n",
        "epistemic_std_dollars = mu_mean_dollars * epistemic_std_log\n",
        "\n",
        "aleatoric_var_log = all_sigma_sq_log.mean(axis=0)\n",
        "aleatoric_std_log = np.sqrt(aleatoric_var_log)\n",
        "aleatoric_std_dollars = mu_mean_dollars * aleatoric_std_log\n",
        "\n",
        "total_std_dollars = np.sqrt(epistemic_std_dollars**2 + aleatoric_std_dollars**2)\n",
        "\n",
        "r2 = r2_score(y_test_raw, mu_mean_dollars)\n",
        "print(f\"R2 (dollars): {r2:.4f}\")\n",
        "print(f\"Epistemic std: mean=${epistemic_std_dollars.mean():,.0f}, max=${epistemic_std_dollars.max():,.0f}\")\n",
        "print(f\"Aleatoric std:  mean=${aleatoric_std_dollars.mean():,.0f}, max=${aleatoric_std_dollars.max():,.0f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "43b8f8c1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization: scatter (colored by uncertainty) + uncertainty decomposition"
      ],
      "id": "b0f56f05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, (ax2, ax3) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "sc = ax2.scatter(y_test_raw, mu_mean_dollars, c=total_std_dollars, cmap=\"magma\", alpha=0.5, s=15)\n",
        "ax2.plot([y_test_raw.min(), y_test_raw.max()], [y_test_raw.min(), y_test_raw.max()], \"r--\", lw=2)\n",
        "plt.colorbar(sc, ax=ax2, label=\"Total Uncertainty ($)\")\n",
        "ax2.set_title(f\"Test Performance (R2: {r2:.3f})\", fontsize=14, fontweight=\"bold\")\n",
        "ax2.set_xlabel(\"Actual Price ($)\")\n",
        "ax2.set_ylabel(\"Predicted Price ($)\")\n",
        "\n",
        "ax3.hist(epistemic_std_dollars, bins=30, alpha=0.5, label=\"Epistemic (Model Doubt)\", color=\"blue\")\n",
        "ax3.hist(aleatoric_std_dollars, bins=30, alpha=0.5, label=\"Aleatoric (Data Noise)\", color=\"red\")\n",
        "ax3.set_title(\"Where does the doubt come from?\", fontsize=14, fontweight=\"bold\")\n",
        "ax3.set_xlabel(\"Standard Deviation ($)\")\n",
        "ax3.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e322184f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Point-wise coverage: Gaussian (per-pass 95% capture)"
      ],
      "id": "a1bfa503"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sigma_samples_log = np.sqrt(all_sigma_sq_log)\n",
        "individual_hit_mask = (\n",
        "    (y_test_raw >= np.exp(all_mu_log - 1.96 * sigma_samples_log)) &\n",
        "    (y_test_raw <= np.exp(all_mu_log + 1.96 * sigma_samples_log))\n",
        ")\n",
        "house_hit_rates = np.mean(individual_hit_mask, axis=0)\n",
        "print(f\"Average Gaussian hit rate across houses: {np.mean(house_hit_rates):.2%}\")\n",
        "\n",
        "df_trend = pd.DataFrame({\"price\": y_test_raw, \"hit_rate\": house_hit_rates}).sort_values(\"price\")\n",
        "df_trend[\"rolling_avg\"] = df_trend[\"hit_rate\"].rolling(window=150, center=True).mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(y_test_raw, house_hit_rates, alpha=0.3, c=house_hit_rates, cmap=\"RdYlGn\", s=15)\n",
        "plt.plot(df_trend[\"price\"], df_trend[\"rolling_avg\"], color=\"blue\", lw=3, label=\"Local Reliability Trend\")\n",
        "plt.axhline(0.95, color=\"black\", linestyle=\"--\", alpha=0.6, label=\"95% Target\")\n",
        "plt.title(\"Gaussian Consensus: How many MC passes captured the truth?\", fontsize=14)\n",
        "plt.xlabel(\"Actual House Price ($)\")\n",
        "plt.ylabel(\"Hit Rate (Fraction of MC Passes)\")\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.colorbar(label=\"Consensus Score\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2dd3f148"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Point-wise coverage: Empirical (simulated samples, 2.5–97.5%)"
      ],
      "id": "74bb4304"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "full_samples_dollars = np.exp(np.random.normal(loc=all_mu_log, scale=np.sqrt(all_sigma_sq_log)))\n",
        "emp_lower = np.percentile(full_samples_dollars, 2.5, axis=0)\n",
        "emp_upper = np.percentile(full_samples_dollars, 97.5, axis=0)\n",
        "emp_hit_mask = (y_test_raw >= emp_lower) & (y_test_raw <= emp_upper)\n",
        "emp_coverage = np.mean(emp_hit_mask)\n",
        "print(f\"Empirical 95% coverage: {emp_coverage:.2%}\")\n",
        "if emp_coverage < 0.90:\n",
        "    print(\"Coverage is low; model may be overconfident.\")\n",
        "else:\n",
        "    print(\"Target hit: uncertainty captures reality well.\")\n",
        "\n",
        "emp_hits = emp_hit_mask.astype(int)\n",
        "jitter = np.random.uniform(-0.05, 0.05, size=len(emp_hits))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(y_test_raw, emp_hits + jitter, alpha=0.2, c=emp_hits, cmap=\"RdYlGn\", s=10)\n",
        "df_rel = pd.DataFrame({\"price\": y_test_raw, \"hit\": emp_hits}).sort_values(\"price\")\n",
        "df_rel[\"rolling_coverage\"] = df_rel[\"hit\"].rolling(window=100, center=True).mean()\n",
        "plt.plot(df_rel[\"price\"], df_rel[\"rolling_coverage\"], color=\"blue\", lw=3, label=\"Local Coverage (Rolling Mean)\")\n",
        "plt.axhline(0.95, color=\"red\", linestyle=\"--\", label=\"95% Target\")\n",
        "plt.title(\"Empirical Reliability: Where do simulations fail?\", fontsize=14)\n",
        "plt.xlabel(\"Actual House Price ($)\")\n",
        "plt.ylabel(\"Hit (1) or Miss (0)\")\n",
        "plt.yticks([0, 1], [\"Miss\", \"Hit\"])\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e172e8c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP: surgical predictors (Price, Epistemic, Aleatoric)"
      ],
      "id": "5301916b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def predict_mean_final(x_np):\n",
        "    preds = model(x_np, training=False).numpy()\n",
        "    mu_log = preds[:, 0]\n",
        "    return np.exp(mu_log)\n",
        "\n",
        "def predict_epistemic_final(x_np):\n",
        "    preds = np.stack([model(x_np, training=True).numpy() for _ in range(50)])\n",
        "    all_mu_log = preds[:, :, 0]\n",
        "    all_mu_dollars = np.exp(all_mu_log)\n",
        "    return all_mu_dollars.std(axis=0)\n",
        "\n",
        "def predict_aleatoric_final(x_np):\n",
        "    preds = model(x_np, training=False).numpy()\n",
        "    mu_log = preds[:, 0]\n",
        "    sigma_sq_log = preds[:, 1].flatten()\n",
        "    aleatoric_std_log = np.sqrt(sigma_sq_log)\n",
        "    return np.exp(mu_log) * aleatoric_std_log\n",
        "\n",
        "X_subset = X_test[:40]\n",
        "background_vibrant = shap.sample(X_train, 100)\n",
        "\n",
        "surgical_predictors = {\n",
        "    \"Price (Mean)\": predict_mean_final,\n",
        "    \"Model Doubt (Epistemic)\": predict_epistemic_final,\n",
        "    \"Data Noise (Aleatoric)\": predict_aleatoric_final,\n",
        "}\n",
        "\n",
        "test_prices = predict_mean_final(X_subset)\n",
        "print(\"Pulse check:\", f\"Sample 1: ${test_prices[0]:,.2f}\", f\"Sample 2: ${test_prices[1]:,.2f}\", f\"Std: {test_prices.std():.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9ec3e822"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP summary plots (beeswarm) for all three heads"
      ],
      "id": "20c198f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for title, func in surgical_predictors.items():\n",
        "    print(f\"Deep-scanning {title}...\")\n",
        "    explainer = shap.KernelExplainer(func, background_vibrant)\n",
        "    sv = explainer.shap_values(X_subset, nsamples=500)\n",
        "    if isinstance(sv, list):\n",
        "        sv = sv[0]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(sv, X_subset, feature_names=feature_cols, show=False)\n",
        "    plt.title(f\"Surgical Focus: {title}\", fontsize=16, fontweight=\"bold\")\n",
        "    plt.xlabel(\"Impact in Dollars ($)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "98566690"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependence plots (one feature vs SHAP)\n",
        "\n",
        "Similar to partial dependence: how does one feature drive Price, Epistemic, or Aleatoric?"
      ],
      "id": "0f24d520"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pick a numeric feature that exists in feature_names (e.g. GROSS SQUARE FEET or affluence_score)\n",
        "target_feature = \"GROSS SQUARE FEET\" if \"GROSS SQUARE FEET\" in feature_names else feature_names[0]\n",
        "explanations = {}\n",
        "for title, func in surgical_predictors.items():\n",
        "    expl = shap.KernelExplainer(func, background_vibrant)\n",
        "    sv = expl.shap_values(X_subset, nsamples=500)\n",
        "    if isinstance(sv, list):\n",
        "        sv = sv[0]\n",
        "    explanations[title] = shap.Explanation(\n",
        "        values=sv, data=X_subset, feature_names=feature_cols, base_values=expl.expected_value\n",
        "    )\n",
        "for title, exp in explanations.items():\n",
        "    if target_feature not in feature_names:\n",
        "        continue\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.plots.scatter(exp[:, target_feature], color=exp, show=False)\n",
        "    plt.title(f\"Dependency: {target_feature} vs {title}\", fontsize=14, fontweight=\"bold\")\n",
        "    plt.ylabel(\"SHAP Value (Impact in $)\")\n",
        "    plt.xlabel(f\"Actual {target_feature} Value\")\n",
        "    plt.grid(alpha=0.2, linestyle=\"--\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "596eaa7c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the most uncertain house"
      ],
      "id": "c44f57a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_unc_idx = np.argmax(total_std_dollars)\n",
        "print(f\"Row with highest combined uncertainty: {max_unc_idx}\")\n",
        "print(f\"Total Std: ${total_std_dollars[max_unc_idx]:,.2f}\")\n",
        "print(f\"  Epistemic: ${epistemic_std_dollars[max_unc_idx]:,.2f} | Aleatoric: ${aleatoric_std_dollars[max_unc_idx]:,.2f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "884ba52c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Waterfall: Price (mean) for most uncertain house"
      ],
      "id": "c441f449"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "explainer_waterfall = shap.KernelExplainer(predict_mean_final, background_vibrant)\n",
        "shap_values_single = explainer_waterfall.shap_values(X_test[max_unc_idx : max_unc_idx + 1], nsamples=1000)\n",
        "if isinstance(shap_values_single, list):\n",
        "    shap_values_single = shap_values_single[0]\n",
        "exp_single = shap.Explanation(\n",
        "    values=shap_values_single[0],\n",
        "    base_values=explainer_waterfall.expected_value,\n",
        "    data=X_test[max_unc_idx],\n",
        "    feature_names=feature_cols\n",
        ")\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.plots.waterfall(exp_single, show=False)\n",
        "plt.title(f\"Why is House #{max_unc_idx} priced at ${predict_mean_final(X_test[max_unc_idx:max_unc_idx+1])[0]:,.0f}?\", fontsize=14, fontweight=\"bold\", pad=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "486ee13d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Waterfalls: Epistemic & Aleatoric for most uncertain house"
      ],
      "id": "577f2f21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "uncertainty_targets = {\n",
        "    \"Model Doubt (Epistemic)\": predict_epistemic_final,\n",
        "    \"Data Noise (Aleatoric)\": predict_aleatoric_final,\n",
        "}\n",
        "for title, func in uncertainty_targets.items():\n",
        "    explainer = shap.KernelExplainer(func, background_vibrant)\n",
        "    sv = explainer.shap_values(X_test[max_unc_idx : max_unc_idx + 1], nsamples=1000)\n",
        "    if isinstance(sv, list):\n",
        "        sv = sv[0]\n",
        "    exp = shap.Explanation(\n",
        "        values=sv[0],\n",
        "        base_values=explainer.expected_value,\n",
        "        data=X_test[max_unc_idx],\n",
        "        feature_names=feature_cols\n",
        "    )\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.plots.waterfall(exp, show=False)\n",
        "    plt.title(f\"Uncertainty Driver: {title} (Row {max_unc_idx})\", fontsize=14, fontweight=\"bold\", pad=20)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0669553f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2D Trust Map: SHAP magnitude vs uncertainty magnitude (quadrants)"
      ],
      "id": "3ddc24a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Generating SHAP values for all targets...\")\n",
        "targets = {\"mean\": predict_mean_final, \"epistemic\": predict_epistemic_final, \"aleatoric\": predict_aleatoric_final}\n",
        "sv_results = {}\n",
        "for name, func in targets.items():\n",
        "    explainer = shap.KernelExplainer(func, background_vibrant)\n",
        "    sv = explainer.shap_values(X_subset, nsamples=500)\n",
        "    if isinstance(sv, list):\n",
        "        sv = sv[0]\n",
        "    sv_results[name] = sv\n",
        "\n",
        "shap_mag = np.abs(sv_results[\"mean\"]).sum(axis=1)\n",
        "unc_mag = np.abs(sv_results[\"epistemic\"]).sum(axis=1) + np.abs(sv_results[\"aleatoric\"]).sum(axis=1)\n",
        "\n",
        "quad_df = pd.DataFrame({\"idx\": np.arange(len(X_subset)), \"shap_mag\": shap_mag, \"unc_mag\": unc_mag})\n",
        "s_mid = quad_df[\"shap_mag\"].median()\n",
        "u_mid = quad_df[\"unc_mag\"].median()\n",
        "\n",
        "def assign_quadrant(row):\n",
        "    if row[\"shap_mag\"] >= s_mid and row[\"unc_mag\"] < u_mid:\n",
        "        return \"High SHAP, Low Unc\"\n",
        "    if row[\"shap_mag\"] >= s_mid and row[\"unc_mag\"] >= u_mid:\n",
        "        return \"High SHAP, High Unc\"\n",
        "    if row[\"shap_mag\"] < s_mid and row[\"unc_mag\"] < u_mid:\n",
        "        return \"Low SHAP, Low Unc\"\n",
        "    return \"Low SHAP, High Unc\"\n",
        "\n",
        "quad_df[\"category\"] = quad_df.apply(assign_quadrant, axis=1)\n",
        "print(quad_df[\"category\"].value_counts())\n",
        "\n",
        "categories = {\n",
        "    \"High SHAP, Low Unc\": {\"color\": \"#1f77b4\", \"desc\": \"(Confident Signal)\"},\n",
        "    \"High SHAP, High Unc\": {\"color\": \"#ff7f0e\", \"desc\": \"(Strong Claim, Low Confidence)\"},\n",
        "    \"Low SHAP, Low Unc\": {\"color\": \"#2ca02c\", \"desc\": \"(Boring but Reliable)\"},\n",
        "    \"Low SHAP, High Unc\": {\"color\": \"#d62728\", \"desc\": \"(Uncertain & Uninformative)\"},\n",
        "}\n",
        "plt.figure(figsize=(10, 7))\n",
        "for label, info in categories.items():\n",
        "    mask = quad_df[\"category\"] == label\n",
        "    plt.scatter(quad_df.loc[mask, \"shap_mag\"], quad_df.loc[mask, \"unc_mag\"], c=info[\"color\"],\n",
        "                label=f\"{label} {info['desc']}\", alpha=0.7, edgecolors=\"w\", s=100)\n",
        "plt.axvline(s_mid, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
        "plt.axhline(u_mid, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
        "plt.xlabel(r\"SHAP Magnitude (Strength of Evidence in $)\")\n",
        "plt.ylabel(r\"Total Uncertainty Impact ($)\")\n",
        "plt.title(\"The Trust Map: Evidence vs. Confidence\", fontsize=14, fontweight=\"bold\")\n",
        "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "plt.grid(alpha=0.2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c8afadef"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample one point from each quadrant and waterfall\n",
        "\n",
        "Compare the \"Gold Standard\" (High SHAP, Low Uncertainty) house vs the \"High Chaos\" house across Price, Epistemic, and Aleatoric."
      ],
      "id": "46aa7875"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    row_HS_LU = quad_df[quad_df[\"category\"] == \"High SHAP, Low Unc\"][\"shap_mag\"].idxmax()\n",
        "    row_chaos = quad_df[\"unc_mag\"].idxmax()\n",
        "    cat_LU, cat_chaos = \"Gold Standard (Confident)\", \"High Chaos (Unreliable)\"\n",
        "    print(f\"Selected: Row {row_HS_LU} (Confident) and {row_chaos} (Chaos)\")\n",
        "except Exception:\n",
        "    row_HS_LU = 0\n",
        "    row_chaos = max_unc_idx\n",
        "    cat_LU, cat_chaos = \"Sample\", \"Most Uncertain\"\n",
        "\n",
        "def plot_surgical_comparison(idx, category_name):\n",
        "    exps = {\n",
        "        \"PRICE DRIVERS ($)\": sv_results.get(\"mean\"),\n",
        "        \"MODEL DOUBT (Epistemic $)\": sv_results.get(\"epistemic\"),\n",
        "        \"DATA NOISE (Aleatoric $)\": sv_results.get(\"aleatoric\"),\n",
        "    }\n",
        "    for title, values in exps.items():\n",
        "        if values is None:\n",
        "            continue\n",
        "        exp_obj = shap.Explanation(\n",
        "            values=values[idx],\n",
        "            base_values=explainer_waterfall.expected_value if \"PRICE\" in title else 0,\n",
        "            data=X_subset[idx],\n",
        "            feature_names=feature_cols,\n",
        "        )\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        shap.plots.waterfall(exp_obj, max_display=7, show=False)\n",
        "        plt.title(f\"{title} | Row {idx} | {category_name}\", fontsize=12, fontweight=\"bold\", pad=20)\n",
        "        plt.show()\n",
        "\n",
        "print(\"--- Confident house ---\")\n",
        "plot_surgical_comparison(row_HS_LU, cat_LU)\n",
        "print(\"--- High chaos house ---\")\n",
        "plot_surgical_comparison(row_chaos, cat_chaos)"
      ],
      "id": "ca1c2520",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 95% interval summary and optional report export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "z = 1.96\n",
        "lower = mu_mean_dollars - z * total_std_dollars\n",
        "upper = mu_mean_dollars + z * total_std_dollars\n",
        "hits = (y_test_raw >= lower) & (y_test_raw <= upper)\n",
        "coverage = hits.mean()\n",
        "print(f\"95% Gaussian interval coverage: {coverage:.2%} (target: 95%)\")\n",
        "\n",
        "if os.environ.get(\"GCS_BUCKET\") or os.environ.get(\"CI\"):\n",
        "    try:\n",
        "        report_dir = os.path.join(os.path.dirname(os.path.abspath(\".\")), \"reports\")\n",
        "    except Exception:\n",
        "        report_dir = os.path.join(os.getcwd(), \"reports\")\n",
        "    os.makedirs(report_dir, exist_ok=True)\n",
        "    report_df = pd.DataFrame({\n",
        "        \"actual_price\": y_test_raw,\n",
        "        \"predicted_price\": mu_mean_dollars,\n",
        "        \"epistemic_std\": epistemic_std_dollars,\n",
        "        \"aleatoric_std\": aleatoric_std_dollars,\n",
        "        \"total_std\": total_std_dollars,\n",
        "        \"in_95_interval\": hits,\n",
        "    })\n",
        "    report_path = os.path.join(report_dir, \"uncertainty_report.csv\")\n",
        "    report_df.to_csv(report_path, index=False)\n",
        "    print(f\"Saved report to {report_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.13.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}